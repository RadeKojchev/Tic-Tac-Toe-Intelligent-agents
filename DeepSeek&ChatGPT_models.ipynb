{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of the notebook"
      ],
      "metadata": {
        "id": "LVV8r86G55LQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook there is the code and the results of the experiment I performed to see whether ChatGPT, to be more precise the curently free trial version GPT-4-Turbo, or DeepSeek-V3 would create a better tic-tac-toe agent using supervised learning. This experiment was conducted out of pure curiosity and with the aim of incorporating it into a broader work in the field of Intelligent Agents, more specifically building a tic-tac-toe agent that perfects the game, testing them against each other and against a perfect model"
      ],
      "metadata": {
        "id": "AeBC1k5C6Csp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepSeek Agents"
      ],
      "metadata": {
        "id": "MikrpYiw5vSj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5EOnXGWe-pU",
        "outputId": "c6b47c27-7d73-4e94-a16d-845b3723f54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0413\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0367\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0345\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0334\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0328\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0325\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0324\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0324\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0324\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0323\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0323\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0323\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0323\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0323\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0323\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0323\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0322\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0322\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0322\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "# Define the Tic Tac Toe environment\n",
        "def initialize_board():\n",
        "    \"\"\"Initialize an empty 3x3 Tic Tac Toe board.\"\"\"\n",
        "    return np.zeros((3, 3), dtype=int)\n",
        "\n",
        "def is_winner(board, player):\n",
        "    \"\"\"Check if the given player has won the game.\"\"\"\n",
        "    for i in range(3):\n",
        "        if all(board[i, :] == player) or all(board[:, i] == player):\n",
        "            return True\n",
        "    if all([board[i, i] == player for i in range(3)]) or all([board[i, 2 - i] == player for i in range(3)]):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def is_draw(board):\n",
        "    \"\"\"Check if the game is a draw.\"\"\"\n",
        "    return np.all(board != 0)\n",
        "\n",
        "def available_moves(board):\n",
        "    \"\"\"Get a list of available moves on the board.\"\"\"\n",
        "    return [(i, j) for i in range(3) for j in range(3) if board[i, j] == 0]\n",
        "\n",
        "def make_move(board, move, player):\n",
        "    \"\"\"Make a move on the board for the given player.\"\"\"\n",
        "    board[move] = player\n",
        "\n",
        "def generate_similar_games():\n",
        "    \"\"\"Generate game states similar to scenarios where the model struggled.\"\"\"\n",
        "    games = []\n",
        "    for _ in range(100):\n",
        "        board = initialize_board()\n",
        "        # Scenario: Opponent is about to win unless blocked\n",
        "        board[0, 2], board[1, 1], board[2, 0] = -1, -1, 0\n",
        "        games.append((board, -1))  # -1's turn\n",
        "\n",
        "        board = initialize_board()\n",
        "        # Scenario: A winning move is available\n",
        "        board[0, 0], board[1, 1], board[0, 1] = 1, 1, 0\n",
        "        games.append((board, 1))  # 1's turn\n",
        "\n",
        "    return games\n",
        "\n",
        "# Define the improved model\n",
        "def create_improved_model():\n",
        "    \"\"\"Create a CNN-based model for Tic Tac Toe.\"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (2, 2), activation=\"relu\", input_shape=(3, 3, 1)),  # Convolutional layer\n",
        "        Flatten(),  # Flatten the output\n",
        "        Dense(128, activation=\"relu\"),  # Fully connected layer\n",
        "        Dense(64, activation=\"relu\"),   # Another fully connected layer\n",
        "        Dense(9, activation=\"linear\")   # Output layer for 9 possible moves\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")  # Mean Squared Error loss\n",
        "    return model\n",
        "\n",
        "# Encode the board state\n",
        "def encode_board(board):\n",
        "    \"\"\"Encode the board state into a 3x3x1 tensor.\"\"\"\n",
        "    return board.reshape(3, 3, 1)\n",
        "\n",
        "# Choose a move based on the model's prediction\n",
        "def choose_move(model, board, epsilon=0.1):\n",
        "    \"\"\"Choose a move using an epsilon-greedy strategy.\"\"\"\n",
        "    if np.random.rand() < epsilon:\n",
        "        return random.choice(available_moves(board))  # Explore: choose a random move\n",
        "    predictions = model.predict(np.expand_dims(encode_board(board), axis=0), verbose=0)\n",
        "    sorted_moves = np.argsort(predictions[0])[::-1]  # Sort moves by predicted value\n",
        "    for move in sorted_moves:\n",
        "        x, y = divmod(move, 3)  # Convert flat index to (x, y) coordinates\n",
        "        if (x, y) in available_moves(board):\n",
        "            return (x, y)  # Exploit: choose the best valid move\n",
        "\n",
        "# Experience replay buffer\n",
        "class ReplayBuffer:\n",
        "    \"\"\"A buffer to store and sample past experiences for training.\"\"\"\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def add(self, experience):\n",
        "        \"\"\"Add an experience to the buffer.\"\"\"\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Sample a batch of experiences from the buffer.\"\"\"\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Get the current size of the buffer.\"\"\"\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Train the model with experience replay\n",
        "def train_model_with_replay(model, buffer, batch_size=32, epochs=10):\n",
        "    \"\"\"Train the model using experiences sampled from the replay buffer.\"\"\"\n",
        "    if len(buffer) < batch_size:\n",
        "        return  # Not enough experiences to sample\n",
        "\n",
        "    samples = buffer.sample(batch_size)\n",
        "    x_train, y_train = [], []\n",
        "\n",
        "    for board, move, reward in samples:\n",
        "        x_train.append(encode_board(board))  # Encode the board state\n",
        "        target = model.predict(np.expand_dims(encode_board(board), axis=0), verbose=0)[0]\n",
        "        target[move[0] * 3 + move[1]] = reward  # Update the target for the chosen move\n",
        "        y_train.append(target)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "    model.fit(x_train, y_train, epochs=epochs, verbose=1)  # Train the model\n",
        "\n",
        "# Self-play with experience replay\n",
        "def self_play_training_with_replay(model, buffer, iterations=100):\n",
        "    \"\"\"Train the model through self-play and store experiences in the replay buffer.\"\"\"\n",
        "    for _ in range(iterations):\n",
        "        state = initialize_board()\n",
        "        player = 1\n",
        "        history = []\n",
        "\n",
        "        while True:\n",
        "            move = choose_move(model, state)  # Choose a move\n",
        "            make_move(state, move, player)  # Apply the move\n",
        "            history.append((state.copy(), move, player))  # Store the state and move\n",
        "\n",
        "            winner = is_winner(state, player)\n",
        "            if winner or is_draw(state):\n",
        "                # Assign rewards based on the game outcome\n",
        "                reward = 1 if winner else 0.5\n",
        "                for past_state, past_move, past_player in reversed(history):\n",
        "                    buffer.add((past_state, past_move, reward))  # Add experience to the buffer\n",
        "                    reward *= 0.9  # Discount factor for earlier moves\n",
        "                break\n",
        "\n",
        "            player = -player  # Switch players\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    \"\"\"Main function to train and save the improved Tic Tac Toe model.\"\"\"\n",
        "    model = create_improved_model()\n",
        "    buffer = ReplayBuffer(capacity=10000)\n",
        "\n",
        "    # Targeted training based on scenarios where the model struggled\n",
        "    similar_games = generate_similar_games()\n",
        "    for board, player in similar_games:\n",
        "        moves = available_moves(board)\n",
        "        for move in moves:\n",
        "            temp_board = board.copy()\n",
        "            make_move(temp_board, move, player)\n",
        "            reward = 1 if is_winner(temp_board, player) else 0.5\n",
        "            buffer.add((board, move, reward))  # Add experiences to the buffer\n",
        "\n",
        "    train_model_with_replay(model, buffer, epochs=20)  # Train the model\n",
        "\n",
        "    # Self-play to refine strategies\n",
        "    self_play_training_with_replay(model, buffer, iterations=100)\n",
        "\n",
        "    # Save the updated model\n",
        "    model.save(\"DeepSeekRNN.h5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from functools import lru_cache\n",
        "\n",
        "# Constants\n",
        "class Config:\n",
        "    BOARD_SIZE = 3\n",
        "    NUM_TRAINING_SAMPLES = 2000\n",
        "    PLAYERS = {'X': 1, 'O': -1}\n",
        "    DEPTH = 5\n",
        "\n",
        "# Create an empty board\n",
        "def create_board():\n",
        "    return np.zeros((Config.BOARD_SIZE, Config.BOARD_SIZE), dtype=int)\n",
        "\n",
        "# Get valid moves\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(Config.BOARD_SIZE) for j in range(Config.BOARD_SIZE) if board[i, j] == 0]\n",
        "\n",
        "# Apply a move to the board\n",
        "def apply_move(board, move, player):\n",
        "    if move not in get_valid_moves(board):\n",
        "        raise ValueError(f\"Invalid move: {move}\")\n",
        "    board[move[0], move[1]] = player\n",
        "\n",
        "# Check for a winner\n",
        "def check_winner(board):\n",
        "    for i in range(Config.BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == Config.BOARD_SIZE:  # Row check\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == Config.BOARD_SIZE:  # Column check\n",
        "            return np.sign(sum(board[:, i]))\n",
        "\n",
        "    # Diagonals\n",
        "    if abs(sum([board[i, i] for i in range(Config.BOARD_SIZE)])) == Config.BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, i] for i in range(Config.BOARD_SIZE)]))\n",
        "    if abs(sum([board[i, Config.BOARD_SIZE - i - 1] for i in range(Config.BOARD_SIZE)])) == Config.BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, Config.BOARD_SIZE - i - 1] for i in range(Config.BOARD_SIZE)]))\n",
        "\n",
        "    if 0 not in board:\n",
        "        return 0  # Draw\n",
        "\n",
        "    return None  # Game ongoing\n",
        "\n",
        "# Minimax with alpha-beta pruning and memoization\n",
        "@lru_cache(maxsize=None)\n",
        "def minimax(board_tuple, depth, maximizing_player, alpha=-math.inf, beta=math.inf):\n",
        "    # Convert the tuple back to a numpy array for processing\n",
        "    board = np.array(board_tuple).reshape(Config.BOARD_SIZE, Config.BOARD_SIZE)\n",
        "\n",
        "    winner = check_winner(board)\n",
        "    if winner is not None or depth == 0:\n",
        "        return winner or 0  # 1 for win, -1 for loss, 0 for draw\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "\n",
        "    if maximizing_player:\n",
        "        max_eval = -math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, 1)\n",
        "            # Convert the board to a tuple before passing it to minimax\n",
        "            eval = minimax(tuple(temp_board.ravel()), depth - 1, False, alpha, beta)\n",
        "            max_eval = max(max_eval, eval)\n",
        "            alpha = max(alpha, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return max_eval\n",
        "    else:\n",
        "        min_eval = math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, -1)\n",
        "            # Convert the board to a tuple before passing it to minimax\n",
        "            eval = minimax(tuple(temp_board.ravel()), depth - 1, True, alpha, beta)\n",
        "            min_eval = min(min_eval, eval)\n",
        "            beta = min(beta, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_eval\n",
        "\n",
        "def minimax_move(board, player, depth=Config.DEPTH):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    best_move = None\n",
        "    best_value = -math.inf if player == 1 else math.inf\n",
        "\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        # Convert the board to a tuple before passing it to minimax\n",
        "        move_value = minimax(tuple(temp_board.ravel()), depth - 1, player == -1)\n",
        "\n",
        "        if (player == 1 and move_value > best_value) or (player == -1 and move_value < best_value):\n",
        "            best_value = move_value\n",
        "            best_move = move\n",
        "\n",
        "    return best_move\n",
        "# Random player\n",
        "def random_move(board, player):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    return random.choice(valid_moves) if valid_moves else None\n",
        "\n",
        "# Heuristic player\n",
        "def heuristic_move(board, player):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    if not valid_moves:\n",
        "        return None\n",
        "\n",
        "    # Try to win immediately\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        if check_winner(temp_board) == player:\n",
        "            return move\n",
        "\n",
        "    # Try to block opponent's winning move\n",
        "    opponent = -player\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, opponent)\n",
        "        if check_winner(temp_board) == opponent:\n",
        "            return move\n",
        "\n",
        "    # Take the center if available\n",
        "    if (1, 1) in valid_moves:\n",
        "        return (1, 1)\n",
        "\n",
        "    # Take a corner if available\n",
        "    corners = [(0, 0), (0, 2), (2, 0), (2, 2)]\n",
        "    for corner in corners:\n",
        "        if corner in valid_moves:\n",
        "            return corner\n",
        "\n",
        "    # Take any available move\n",
        "    return random.choice(valid_moves)\n",
        "\n",
        "# Generate training data\n",
        "def generate_training_data(num_samples):\n",
        "    X_data, y_data = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        board = create_board()\n",
        "        moves = []\n",
        "        player = 1 if random.random() < 0.5 else -1\n",
        "        winner = None\n",
        "\n",
        "        while True:\n",
        "            valid_moves = get_valid_moves(board)\n",
        "\n",
        "            # Choose player strategy\n",
        "            player_type = random.choice([\"minimax\", \"random\", \"heuristic\"])\n",
        "\n",
        "            if player_type == \"minimax\":\n",
        "                move = minimax_move(board, player, depth=3)\n",
        "            elif player_type == \"random\":\n",
        "                move = random_move(board, player)\n",
        "            elif player_type == \"heuristic\":\n",
        "                move = heuristic_move(board, player)\n",
        "\n",
        "            if move is None:\n",
        "                break\n",
        "\n",
        "            apply_move(board, move, player)\n",
        "            moves.append((board.copy(), move, player))\n",
        "\n",
        "            winner = check_winner(board)\n",
        "            if winner is not None:\n",
        "                break\n",
        "            player *= -1\n",
        "\n",
        "        for board_state, move, player in moves:\n",
        "            X_data.append(board_state)\n",
        "            y_data.append(move[0] * Config.BOARD_SIZE + move[1])\n",
        "\n",
        "    X_data = np.array(X_data).reshape(-1, Config.BOARD_SIZE, Config.BOARD_SIZE, 1)\n",
        "    y_data_moves = tf.keras.utils.to_categorical(y_data, num_classes=Config.BOARD_SIZE**2)\n",
        "    return X_data, y_data_moves\n",
        "\n",
        "# Build the model\n",
        "def build_model():\n",
        "    inputs = Input(shape=(Config.BOARD_SIZE, Config.BOARD_SIZE, 1))\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    move_output = Dense(Config.BOARD_SIZE**2, activation='softmax', name='move_output')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=move_output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Predict move\n",
        "def predict_move(model, board, player):\n",
        "    board_input = board.copy() * player\n",
        "    board_input = board_input.reshape(1, Config.BOARD_SIZE, Config.BOARD_SIZE, 1)\n",
        "    predictions = model.predict(board_input, verbose=0)[0]\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    move_probs = np.zeros_like(predictions)\n",
        "    for move in valid_moves:\n",
        "        idx = move[0] * Config.BOARD_SIZE + move[1]\n",
        "        move_probs[idx] = predictions[idx]\n",
        "\n",
        "    best_move_idx = np.argmax(move_probs)\n",
        "    move = (best_move_idx // Config.BOARD_SIZE, best_move_idx % Config.BOARD_SIZE)\n",
        "\n",
        "    if move not in valid_moves:\n",
        "        raise ValueError(f\"Model predicted an invalid move: {move}\")\n",
        "\n",
        "    return move\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating training data...\")\n",
        "    X, y_moves = generate_training_data(Config.NUM_TRAINING_SAMPLES)\n",
        "    print(f\"Training data generated: {X.shape[0]} samples\")\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y_moves, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model()\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(\"Training the model...\")\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=10,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Save the model\n",
        "    model.save(\"DeepSeek CNN.h5\")\n",
        "    print(\"Model trained and saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKKnHl2n-ZDw",
        "outputId": "30d0f838-d786-4c06-cb15-0c12ffdc5795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data...\n",
            "Training data generated: 15097 samples\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2100 - loss: 2.1260 - val_accuracy: 0.4175 - val_loss: 1.7276\n",
            "Epoch 2/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3990 - loss: 1.6973 - val_accuracy: 0.4583 - val_loss: 1.5042\n",
            "Epoch 3/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4582 - loss: 1.5292 - val_accuracy: 0.4917 - val_loss: 1.3941\n",
            "Epoch 4/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4953 - loss: 1.4164 - val_accuracy: 0.5199 - val_loss: 1.3059\n",
            "Epoch 5/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5318 - loss: 1.3212 - val_accuracy: 0.5530 - val_loss: 1.2455\n",
            "Epoch 6/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5486 - loss: 1.2763 - val_accuracy: 0.5579 - val_loss: 1.1905\n",
            "Epoch 7/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5789 - loss: 1.2100 - val_accuracy: 0.5897 - val_loss: 1.1561\n",
            "Epoch 8/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5809 - loss: 1.1834 - val_accuracy: 0.6053 - val_loss: 1.1068\n",
            "Epoch 9/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5940 - loss: 1.1527 - val_accuracy: 0.5983 - val_loss: 1.0968\n",
            "Epoch 10/10\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5913 - loss: 1.1278 - val_accuracy: 0.6189 - val_loss: 1.0501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "# Constants\n",
        "BOARD_SIZE = 3\n",
        "NUM_TRAINING_SAMPLES = 2000\n",
        "\n",
        "# Create an empty board\n",
        "def create_board():\n",
        "    return np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)\n",
        "\n",
        "# Get valid moves\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i, j] == 0]\n",
        "\n",
        "# Apply a move to the board\n",
        "def apply_move(board, move, player):\n",
        "    if move in get_valid_moves(board):\n",
        "        board[move[0], move[1]] = player\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid move: {move}\")\n",
        "\n",
        "# Check for a winner\n",
        "def check_winner(board):\n",
        "    for i in range(BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == BOARD_SIZE:  # Row check\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == BOARD_SIZE:  # Column check\n",
        "            return np.sign(sum(board[:, i]))\n",
        "\n",
        "    # Diagonals\n",
        "    if abs(sum([board[i, i] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, i] for i in range(BOARD_SIZE)]))\n",
        "    if abs(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)]))\n",
        "\n",
        "    if 0 not in board:\n",
        "        return 0  # Draw\n",
        "\n",
        "    return None  # Game ongoing\n",
        "\n",
        "# Minimax with alpha-beta pruning\n",
        "def minimax(board, depth, maximizing_player, alpha=-math.inf, beta=math.inf):\n",
        "    winner = check_winner(board)\n",
        "    if winner is not None or depth == 0:\n",
        "        return winner or 0  # 1 for win, -1 for loss, 0 for draw\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "\n",
        "    if maximizing_player:\n",
        "        max_eval = -math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, 1)\n",
        "            eval = minimax(temp_board, depth - 1, False, alpha, beta)\n",
        "            max_eval = max(max_eval, eval)\n",
        "            alpha = max(alpha, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return max_eval\n",
        "    else:\n",
        "        min_eval = math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, -1)\n",
        "            eval = minimax(temp_board, depth - 1, True, alpha, beta)\n",
        "            min_eval = min(min_eval, eval)\n",
        "            beta = min(beta, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_eval\n",
        "\n",
        "# Choose move using minimax\n",
        "def minimax_move(board, player, depth=5):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    best_move = None\n",
        "    best_value = -math.inf if player == 1 else math.inf\n",
        "\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        move_value = minimax(temp_board, depth - 1, player == -1)\n",
        "\n",
        "        if (player == 1 and move_value > best_value) or (player == -1 and move_value < best_value):\n",
        "            best_value = move_value\n",
        "            best_move = move\n",
        "\n",
        "    return best_move\n",
        "\n",
        "# Random player\n",
        "def random_move(board, player):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    return random.choice(valid_moves) if valid_moves else None\n",
        "\n",
        "# Heuristic player\n",
        "def heuristic_move(board, player):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    if not valid_moves:\n",
        "        return None\n",
        "\n",
        "    # Try to win immediately\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        if check_winner(temp_board) == player:\n",
        "            return move\n",
        "\n",
        "    # Try to block opponent's winning move\n",
        "    opponent = -player\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, opponent)\n",
        "        if check_winner(temp_board) == opponent:\n",
        "            return move\n",
        "\n",
        "    # Take the center if available\n",
        "    if (1, 1) in valid_moves:\n",
        "        return (1, 1)\n",
        "\n",
        "    # Take a corner if available\n",
        "    corners = [(0, 0), (0, 2), (2, 0), (2, 2)]\n",
        "    for corner in corners:\n",
        "        if corner in valid_moves:\n",
        "            return corner\n",
        "\n",
        "    # Take any available move\n",
        "    return random.choice(valid_moves)\n",
        "\n",
        "# Generate training data\n",
        "def generate_training_data(num_samples):\n",
        "    X_data, y_data = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        board = create_board()\n",
        "        moves = []\n",
        "        player = 1 if random.random() < 0.5 else -1\n",
        "        winner = None\n",
        "\n",
        "        while True:\n",
        "            valid_moves = get_valid_moves(board)\n",
        "\n",
        "            # Choose player strategy\n",
        "            player_type = random.choice([\"minimax\", \"random\", \"heuristic\"])\n",
        "\n",
        "            if player_type == \"minimax\":\n",
        "                move = minimax_move(board, player, depth=3)\n",
        "            elif player_type == \"random\":\n",
        "                move = random_move(board, player)\n",
        "            elif player_type == \"heuristic\":\n",
        "                move = heuristic_move(board, player)\n",
        "\n",
        "            if move is None:\n",
        "                break\n",
        "\n",
        "            apply_move(board, move, player)\n",
        "            moves.append((board.copy(), move, player))\n",
        "\n",
        "            winner = check_winner(board)\n",
        "            if winner is not None:\n",
        "                break\n",
        "            player *= -1\n",
        "\n",
        "        for board_state, move, player in moves:\n",
        "            X_data.append(board_state)\n",
        "            y_data.append(move[0] * BOARD_SIZE + move[1])\n",
        "\n",
        "    X_data = np.array(X_data).reshape(-1, BOARD_SIZE, BOARD_SIZE, 1)\n",
        "    y_data_moves = tf.keras.utils.to_categorical(y_data, num_classes=BOARD_SIZE**2)\n",
        "    return X_data, y_data_moves\n",
        "\n",
        "# Build the model\n",
        "def build_model():\n",
        "    inputs = Input(shape=(BOARD_SIZE, BOARD_SIZE, 1))\n",
        "    x = Flatten()(inputs)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    move_output = Dense(BOARD_SIZE**2, activation='softmax', name='move_output')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=move_output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Predict move\n",
        "def predict_move(model, board, player):\n",
        "    board_input = board.copy() * player\n",
        "    board_input = board_input.reshape(1, BOARD_SIZE, BOARD_SIZE, 1)\n",
        "    predictions = model.predict(board_input, verbose=0)[0]\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    move_probs = np.zeros_like(predictions)\n",
        "    for move in valid_moves:\n",
        "        idx = move[0] * BOARD_SIZE + move[1]\n",
        "        move_probs[idx] = predictions[idx]\n",
        "\n",
        "    best_move_idx = np.argmax(move_probs)\n",
        "    move = (best_move_idx // BOARD_SIZE, best_move_idx % BOARD_SIZE)\n",
        "\n",
        "    if move not in valid_moves:\n",
        "        raise ValueError(f\"Model predicted an invalid move: {move}\")\n",
        "\n",
        "    return move\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating training data...\")\n",
        "    X, y_moves = generate_training_data(NUM_TRAINING_SAMPLES)\n",
        "    print(f\"Training data generated: {X.shape[0]} samples\")\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y_moves, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model()\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "    print(\"Training the model...\")\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=20,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping, lr_scheduler]\n",
        "    )\n",
        "\n",
        "    # Save the model\n",
        "    model.save(\"DeepSeek NN.h5\")\n",
        "    print(\"Model trained and saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq6LmXZIBWLE",
        "outputId": "bae9fa23-f7cf-4303-accc-1d042aa76d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data...\n",
            "Training data generated: 15129 samples\n",
            "Training the model...\n",
            "Epoch 1/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.2703 - loss: 2.4741 - val_accuracy: 0.3493 - val_loss: 1.8025 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5005 - loss: 1.4935 - val_accuracy: 0.6186 - val_loss: 1.2162 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5612 - loss: 1.2927 - val_accuracy: 0.6824 - val_loss: 0.9152 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6014 - loss: 1.1529 - val_accuracy: 0.6933 - val_loss: 0.8404 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6180 - loss: 1.0991 - val_accuracy: 0.6943 - val_loss: 0.8192 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6306 - loss: 1.0503 - val_accuracy: 0.7016 - val_loss: 0.7948 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6376 - loss: 1.0129 - val_accuracy: 0.7016 - val_loss: 0.7848 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6429 - loss: 0.9964 - val_accuracy: 0.7089 - val_loss: 0.7730 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6527 - loss: 0.9773 - val_accuracy: 0.6989 - val_loss: 0.7775 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6661 - loss: 0.9366 - val_accuracy: 0.7049 - val_loss: 0.7572 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6578 - loss: 0.9407 - val_accuracy: 0.7112 - val_loss: 0.7487 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6664 - loss: 0.9035 - val_accuracy: 0.7092 - val_loss: 0.7601 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6632 - loss: 0.9075 - val_accuracy: 0.7122 - val_loss: 0.7462 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6710 - loss: 0.8912 - val_accuracy: 0.7065 - val_loss: 0.7434 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6704 - loss: 0.8895 - val_accuracy: 0.7085 - val_loss: 0.7275 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6682 - loss: 0.8853 - val_accuracy: 0.7155 - val_loss: 0.7281 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6776 - loss: 0.8616 - val_accuracy: 0.7079 - val_loss: 0.7249 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6795 - loss: 0.8609 - val_accuracy: 0.7188 - val_loss: 0.7227 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.6805 - loss: 0.8415 - val_accuracy: 0.7171 - val_loss: 0.7115 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6807 - loss: 0.8429 - val_accuracy: 0.7128 - val_loss: 0.7102 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepSeek TOURNAMENT"
      ],
      "metadata": {
        "id": "q56C2nxHDA2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import time\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "BOARD_SIZE = 3\n",
        "model1 = load_model(\"DeepSeek NN.h5\", custom_objects={\"mse\": MeanSquaredError()})\n",
        "model2 = load_model(\"DeepSeek CNN.h5\", custom_objects={\"mse\": MeanSquaredError()})\n",
        "model3 = load_model(\"DeepSeekRNN.h5\", custom_objects={\"mse\": MeanSquaredError()})\n",
        "model_names = {\n",
        "    model1: \"DeepSeekNN\",\n",
        "    model2: \"DeepSeekCNN\",\n",
        "    model3: \"DeepSeekRNN\"\n",
        "}\n",
        "def display_board(board):\n",
        "    symbols = {0: '.', 1: 'X', -1: 'O'}\n",
        "    for row in board:\n",
        "        print(\" \".join(symbols[cell] for cell in row))\n",
        "    print(\"\\n\")\n",
        "\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i, j] == 0]\n",
        "def apply_move(board, move, player):\n",
        "    board[move[0], move[1]] = player\n",
        "def check_winner(board):\n",
        "    for i in range(BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[:, i]))\n",
        "\n",
        "\n",
        "    if abs(sum([board[i, i] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, i] for i in range(BOARD_SIZE)]))\n",
        "    if abs(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)]))\n",
        "\n",
        "    if 0 not in board:\n",
        "        return 0\n",
        "\n",
        "    return None\n",
        "def predict_move(model, board, player):\n",
        "    board_input = board.copy() * player\n",
        "\n",
        "    if len(model.input_shape) == 4 and model.input_shape[1:] == (3, 3, 1):\n",
        "        board_input = board_input.reshape(1, BOARD_SIZE, BOARD_SIZE, 1).astype(\"float32\")\n",
        "    elif len(model.input_shape) == 2 and model.input_shape[1] == 9:\n",
        "        board_input = board_input.reshape(1, BOARD_SIZE * BOARD_SIZE).astype(\"float32\")\n",
        "    elif len(model.input_shape) == 3 and model.input_shape[1:] == (9, 1):\n",
        "        board_input = board_input.reshape(1, BOARD_SIZE * BOARD_SIZE, 1).astype(\"float32\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected input shape for the model: {model.input_shape}\")\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        if check_winner(temp_board) == player:\n",
        "            return move\n",
        "\n",
        "    predictions = model.predict(board_input, verbose=0)[0].flatten()\n",
        "    move_probs = np.zeros_like(predictions)\n",
        "    for move in valid_moves:\n",
        "        idx = move[0] * BOARD_SIZE + move[1]\n",
        "        move_probs[idx] = predictions[idx]\n",
        "\n",
        "    best_move_idx = np.argmax(move_probs)\n",
        "    return (best_move_idx // BOARD_SIZE, best_move_idx % BOARD_SIZE)\n",
        "def play_game(model_a, model_b, game_num):\n",
        "    board = np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)\n",
        "    player = 1\n",
        "\n",
        "    print(f\"Game {game_num} starts:\")\n",
        "    while True:\n",
        "        print(f\"Player {player}'s turn:\")\n",
        "        display_board(board)\n",
        "\n",
        "        move = predict_move(model_a if player == 1 else model_b, board, player)\n",
        "        apply_move(board, move, player)\n",
        "        winner = check_winner(board)\n",
        "        if winner is not None:\n",
        "            print(\"\\nFinal Board:\")\n",
        "            display_board(board)\n",
        "            return winner\n",
        "\n",
        "        player *= -1\n",
        "def conduct_tournament(num_games=3):\n",
        "    models = [model1, model2, model3]\n",
        "    scores = {model_names[m]: 0 for m in models}\n",
        "    scores[\"Draw\"] = 0\n",
        "\n",
        "    game_num = 1\n",
        "    for i in range(len(models)):\n",
        "        for j in range(i + 1, len(models)):\n",
        "            model_a, model_b = models[i], models[j]\n",
        "            name_a, name_b = model_names[model_a], model_names[model_b]\n",
        "\n",
        "            for _ in range(num_games):\n",
        "                print(f\"{name_a} vs {name_b}\")\n",
        "                winner = play_game(model_a, model_b, game_num)\n",
        "                if winner == 1:\n",
        "                    print(f\"{name_a} wins!\\n\")\n",
        "                    scores[name_a] += 1\n",
        "                elif winner == -1:\n",
        "                    print(f\"{name_b} wins!\\n\")\n",
        "                    scores[name_b] += 1\n",
        "                else:\n",
        "                    print(\"It's a draw!\\n\")\n",
        "                    scores[\"Draw\"] += 1\n",
        "                game_num += 1\n",
        "                time.sleep(1)\n",
        "\n",
        "            for _ in range(num_games):\n",
        "                print(f\"{name_b} vs {name_a}\")\n",
        "                winner = play_game(model_b, model_a, game_num)\n",
        "                if winner == 1:\n",
        "                    print(f\"{name_b} wins!\\n\")\n",
        "                    scores[name_b] += 1\n",
        "                elif winner == -1:\n",
        "                    print(f\"{name_a} wins!\\n\")\n",
        "                    scores[name_a] += 1\n",
        "                else:\n",
        "                    print(\"It's a draw!\\n\")\n",
        "                    scores[\"Draw\"] += 1\n",
        "                game_num += 1\n",
        "                time.sleep(1)\n",
        "\n",
        "    print(\"Tournament Results:\")\n",
        "    for model, score in scores.items():\n",
        "        print(f\"{model}: {score}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    conduct_tournament(num_games=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7liU5jlC_J0",
        "outputId": "acea7c42-062a-4a45-ea6f-1775e1e57061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepSeekNN vs DeepSeekCNN\n",
            "Game 1 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            "X O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            "X O .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . X\n",
            "X O .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X O X\n",
            "X O .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X O X\n",
            "X O X\n",
            "O . .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "X O X\n",
            "X O X\n",
            "O O .\n",
            "\n",
            "\n",
            "DeepSeekCNN wins!\n",
            "\n",
            "DeepSeekCNN vs DeepSeekNN\n",
            "Game 2 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". O .\n",
            ". X .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            ". O .\n",
            "O X .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            "X O .\n",
            "O X .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "X . O\n",
            "X O .\n",
            "O X .\n",
            "\n",
            "\n",
            "DeepSeekNN wins!\n",
            "\n",
            "DeepSeekNN vs DeepSeekRNN\n",
            "Game 3 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            ". . .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". X .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            ". X .\n",
            "O O .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "X . .\n",
            ". X .\n",
            "O O X\n",
            "\n",
            "\n",
            "DeepSeekNN wins!\n",
            "\n",
            "DeepSeekRNN vs DeepSeekNN\n",
            "Game 4 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . .\n",
            ". . .\n",
            "X . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". O .\n",
            "X . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . .\n",
            ". O .\n",
            "X X .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "O . .\n",
            ". O .\n",
            "X X .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "O . .\n",
            ". O .\n",
            "X X X\n",
            "\n",
            "\n",
            "DeepSeekRNN wins!\n",
            "\n",
            "DeepSeekCNN vs DeepSeekRNN\n",
            "Game 5 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            ". . .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            "X . .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            "X . O\n",
            "O . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . X\n",
            "X . O\n",
            "O . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . X\n",
            "X . O\n",
            "O O .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "X X X\n",
            "X . O\n",
            "O O .\n",
            "\n",
            "\n",
            "DeepSeekCNN wins!\n",
            "\n",
            "DeepSeekRNN vs DeepSeekCNN\n",
            "Game 6 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . .\n",
            ". . .\n",
            "X . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". . .\n",
            "O . .\n",
            "X . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . .\n",
            "O . .\n",
            "X X .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". . .\n",
            "O O .\n",
            "X X .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            ". . .\n",
            "O O .\n",
            "X X X\n",
            "\n",
            "\n",
            "DeepSeekRNN wins!\n",
            "\n",
            "Tournament Results:\n",
            "DeepSeekNN: 2\n",
            "DeepSeekCNN: 2\n",
            "DeepSeekRNN: 2\n",
            "Draw: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT Agents"
      ],
      "metadata": {
        "id": "q4tSxv8L66vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT NN"
      ],
      "metadata": {
        "id": "rsIW6UUD7ClJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "# Constants\n",
        "BOARD_SIZE = 3\n",
        "NUM_TRAINING_SAMPLES = 2000\n",
        "\n",
        "# Create an empty board\n",
        "def create_board():\n",
        "    return np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)\n",
        "\n",
        "# Get valid moves\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i, j] == 0]\n",
        "\n",
        "# Apply a move to the board\n",
        "def apply_move(board, move, player):\n",
        "    if move in get_valid_moves(board):\n",
        "        board[move[0], move[1]] = player\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid move: {move}\")\n",
        "\n",
        "# Check for a winner\n",
        "def check_winner(board):\n",
        "    for i in range(BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == BOARD_SIZE:  # Row check\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == BOARD_SIZE:  # Column check\n",
        "            return np.sign(sum(board[:, i]))\n",
        "\n",
        "    # Diagonals\n",
        "    if abs(sum([board[i, i] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, i] for i in range(BOARD_SIZE)]))\n",
        "    if abs(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)]))\n",
        "\n",
        "    if 0 not in board:\n",
        "        return 0  # Draw\n",
        "\n",
        "    return None  # Game ongoing\n",
        "\n",
        "# Minimax with alpha-beta pruning\n",
        "def minimax(board, depth, maximizing_player, alpha=-math.inf, beta=math.inf):\n",
        "    winner = check_winner(board)\n",
        "    if winner is not None or depth == 0:\n",
        "        return winner or 0  # 1 for win, -1 for loss, 0 for draw\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "\n",
        "    if maximizing_player:\n",
        "        max_eval = -math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, 1)\n",
        "            eval = minimax(temp_board, depth - 1, False, alpha, beta)\n",
        "            max_eval = max(max_eval, eval)\n",
        "            alpha = max(alpha, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return max_eval\n",
        "    else:\n",
        "        min_eval = math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, -1)\n",
        "            eval = minimax(temp_board, depth - 1, True, alpha, beta)\n",
        "            min_eval = min(min_eval, eval)\n",
        "            beta = min(beta, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_eval\n",
        "\n",
        "# Choose move using minimax\n",
        "def minimax_move(board, player, depth=5):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    best_move = None\n",
        "    best_value = -math.inf if player == 1 else math.inf\n",
        "\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        move_value = minimax(temp_board, depth - 1, player == -1)\n",
        "\n",
        "        if (player == 1 and move_value > best_value) or (player == -1 and move_value < best_value):\n",
        "            best_value = move_value\n",
        "            best_move = move\n",
        "\n",
        "    return best_move\n",
        "\n",
        "# Random player\n",
        "def random_move(board, player):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    return random.choice(valid_moves) if valid_moves else None\n",
        "\n",
        "# Heuristic player\n",
        "def heuristic_move(board, player):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    if not valid_moves:\n",
        "        return None\n",
        "\n",
        "    # Try to win immediately\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        if check_winner(temp_board) == player:\n",
        "            return move\n",
        "\n",
        "    # Try to block opponent's winning move\n",
        "    opponent = -player\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, opponent)\n",
        "        if check_winner(temp_board) == opponent:\n",
        "            return move\n",
        "\n",
        "    # Take the center if available\n",
        "    if (1, 1) in valid_moves:\n",
        "        return (1, 1)\n",
        "\n",
        "    # Take a corner if available\n",
        "    corners = [(0, 0), (0, 2), (2, 0), (2, 2)]\n",
        "    for corner in corners:\n",
        "        if corner in valid_moves:\n",
        "            return corner\n",
        "\n",
        "    # Take any available move\n",
        "    return random.choice(valid_moves)\n",
        "\n",
        "# Generate training data\n",
        "def generate_training_data(num_samples):\n",
        "    X_data, y_data = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        board = create_board()\n",
        "        moves = []\n",
        "        player = 1 if random.random() < 0.5 else -1\n",
        "        winner = None\n",
        "\n",
        "        while True:\n",
        "            valid_moves = get_valid_moves(board)\n",
        "\n",
        "            # Choose player strategy\n",
        "            player_type = random.choice([\"minimax\", \"random\", \"heuristic\"])\n",
        "\n",
        "            if player_type == \"minimax\":\n",
        "                move = minimax_move(board, player, depth=3)\n",
        "            elif player_type == \"random\":\n",
        "                move = random_move(board, player)\n",
        "            elif player_type == \"heuristic\":\n",
        "                move = heuristic_move(board, player)\n",
        "\n",
        "            if move is None:\n",
        "                break\n",
        "\n",
        "            apply_move(board, move, player)\n",
        "            moves.append((board.copy(), move, player))\n",
        "\n",
        "            winner = check_winner(board)\n",
        "            if winner is not None:\n",
        "                break\n",
        "            player *= -1\n",
        "\n",
        "        for board_state, move, player in moves:\n",
        "            X_data.append(board_state)\n",
        "            y_data.append(move[0] * BOARD_SIZE + move[1])\n",
        "\n",
        "    X_data = np.array(X_data).reshape(-1, BOARD_SIZE, BOARD_SIZE, 1)\n",
        "    y_data_moves = tf.keras.utils.to_categorical(y_data, num_classes=BOARD_SIZE**2)\n",
        "    return X_data, y_data_moves\n",
        "\n",
        "# Build the model\n",
        "def build_model():\n",
        "    inputs = Input(shape=(BOARD_SIZE, BOARD_SIZE, 1))\n",
        "    x = Flatten()(inputs)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    move_output = Dense(BOARD_SIZE**2, activation='softmax', name='move_output')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=move_output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Predict move\n",
        "def predict_move(model, board, player):\n",
        "    board_input = board.copy() * player\n",
        "    board_input = board_input.reshape(1, BOARD_SIZE, BOARD_SIZE, 1)\n",
        "    predictions = model.predict(board_input, verbose=0)[0]\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    move_probs = np.zeros_like(predictions)\n",
        "    for move in valid_moves:\n",
        "        idx = move[0] * BOARD_SIZE + move[1]\n",
        "        move_probs[idx] = predictions[idx]\n",
        "\n",
        "    best_move_idx = np.argmax(move_probs)\n",
        "    move = (best_move_idx // BOARD_SIZE, best_move_idx % BOARD_SIZE)\n",
        "\n",
        "    if move not in valid_moves:\n",
        "        raise ValueError(f\"Model predicted an invalid move: {move}\")\n",
        "\n",
        "    return move\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating training data...\")\n",
        "    X, y_moves = generate_training_data(NUM_TRAINING_SAMPLES)\n",
        "    print(f\"Training data generated: {X.shape[0]} samples\")\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y_moves, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model()\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(\"Training the model...\")\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=10,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Save the model\n",
        "    model.save(\"tictactoe_GPT_NN_model.h5\")\n",
        "    print(\"Model trained and saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcvw8hhlyzWh",
        "outputId": "51009422-c8b0-4b0e-f679-2b83fa988f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data...\n",
            "Training data generated: 15181 samples\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2576 - loss: 2.0875 - val_accuracy: 0.5390 - val_loss: 1.5392\n",
            "Epoch 2/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5001 - loss: 1.5148 - val_accuracy: 0.6490 - val_loss: 1.1164\n",
            "Epoch 3/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5668 - loss: 1.2439 - val_accuracy: 0.6697 - val_loss: 0.9779\n",
            "Epoch 4/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6002 - loss: 1.1400 - val_accuracy: 0.6862 - val_loss: 0.8985\n",
            "Epoch 5/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6115 - loss: 1.0616 - val_accuracy: 0.7017 - val_loss: 0.8536\n",
            "Epoch 6/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6283 - loss: 1.0214 - val_accuracy: 0.6928 - val_loss: 0.8419\n",
            "Epoch 7/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6361 - loss: 0.9965 - val_accuracy: 0.7083 - val_loss: 0.8180\n",
            "Epoch 8/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6479 - loss: 0.9609 - val_accuracy: 0.6958 - val_loss: 0.8108\n",
            "Epoch 9/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6498 - loss: 0.9475 - val_accuracy: 0.7076 - val_loss: 0.7931\n",
            "Epoch 10/10\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.9259 - val_accuracy: 0.7063 - val_loss: 0.7904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT CNN"
      ],
      "metadata": {
        "id": "w5NC8ydZy5Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import math\n",
        "\n",
        "# Constants\n",
        "BOARD_SIZE = 3\n",
        "NUM_TRAINING_SAMPLES = 8000\n",
        "\n",
        "# Create an empty board\n",
        "def create_board():\n",
        "    return np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)\n",
        "\n",
        "# Get valid moves\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i, j] == 0]\n",
        "\n",
        "# Apply a move to the board\n",
        "def apply_move(board, move, player):\n",
        "    board[move[0], move[1]] = player\n",
        "\n",
        "# Check for a winner\n",
        "def check_winner(board):\n",
        "    for i in range(BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == BOARD_SIZE:  # Row check\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == BOARD_SIZE:  # Column check\n",
        "            return np.sign(sum(board[:, i]))\n",
        "\n",
        "    # Diagonals\n",
        "    if abs(sum([board[i, i] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, i] for i in range(BOARD_SIZE)]))\n",
        "    if abs(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)]))\n",
        "\n",
        "    if 0 not in board:\n",
        "        return 0  # Draw\n",
        "\n",
        "    return None  # Game ongoing\n",
        "\n",
        "# Enhanced heuristic agent with adjacency prioritization\n",
        "def enhanced_heuristic_agent(board, player):\n",
        "    opponent = -player\n",
        "    valid_moves = get_valid_moves(board)\n",
        "\n",
        "    # Check for winning move\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        if check_winner(temp_board) == player:\n",
        "            return move\n",
        "\n",
        "    # Check for blocking move\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, opponent)\n",
        "        if check_winner(temp_board) == opponent:\n",
        "            return move\n",
        "\n",
        "    # Prioritize moves adjacent to existing pieces\n",
        "    adjacent_moves = []\n",
        "    for move in valid_moves:\n",
        "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1), (-1, -1), (1, 1), (-1, 1), (1, -1)]:\n",
        "            adj_x, adj_y = move[0] + dx, move[1] + dy\n",
        "            if 0 <= adj_x < BOARD_SIZE and 0 <= adj_y < BOARD_SIZE and board[adj_x, adj_y] == player:\n",
        "                adjacent_moves.append(move)\n",
        "                break\n",
        "\n",
        "    if adjacent_moves:\n",
        "        return random.choice(adjacent_moves)\n",
        "\n",
        "    # Center\n",
        "    center = ((1, 1))\n",
        "\n",
        "    if center in valid_moves:\n",
        "        return center\n",
        "\n",
        "\n",
        "    return random.choice(valid_moves)\n",
        "\n",
        "def minimax(board, depth, maximizing_player, alpha=-math.inf, beta=math.inf):\n",
        "    winner = check_winner(board)\n",
        "    if winner is not None or depth == 0:\n",
        "        return winner or 0  # 1 for win, -1 for loss, 0 for draw\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "\n",
        "    # Check for immediate winning move and play it\n",
        "    if maximizing_player:\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, 1)  # Player 1\n",
        "            if check_winner(temp_board) == 1:\n",
        "                return 1  # Winning move found\n",
        "    else:\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, -1)  # Player -1\n",
        "            if check_winner(temp_board) == -1:\n",
        "                return -1  # Winning move found\n",
        "\n",
        "    if maximizing_player:\n",
        "        max_eval = -math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, 1)\n",
        "            eval = minimax(temp_board, depth - 1, False, alpha, beta)\n",
        "            max_eval = max(max_eval, eval)\n",
        "            alpha = max(alpha, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return max_eval\n",
        "    else:\n",
        "        min_eval = math.inf\n",
        "        for move in valid_moves:\n",
        "            temp_board = board.copy()\n",
        "            apply_move(temp_board, move, -1)\n",
        "            eval = minimax(temp_board, depth - 1, True, alpha, beta)\n",
        "            min_eval = min(min_eval, eval)\n",
        "            beta = min(beta, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_eval\n",
        "\n",
        "\n",
        "# Smart agent combining heuristic and minimax\n",
        "def smart_agent(board, player):\n",
        "    # Use heuristic for quick checks\n",
        "    move = enhanced_heuristic_agent(board, player)\n",
        "    if move:\n",
        "        return move\n",
        "\n",
        "    # Use minimax for strategic decision-making\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    best_move = None\n",
        "    best_score = -math.inf if player == 1 else math.inf\n",
        "\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        score = minimax(temp_board, depth=3, maximizing_player=(player == 1))\n",
        "        if (player == 1 and score > best_score) or (player == -1 and score < best_score):\n",
        "            best_score = score\n",
        "            best_move = move\n",
        "\n",
        "    return best_move\n",
        "\n",
        "def generate_training_data(num_samples):\n",
        "    X_data, y_data = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "      board = create_board()\n",
        "      moves = []\n",
        "      player = 1\n",
        "\n",
        "    while True:\n",
        "        if player == 1:\n",
        "            move = enhanced_heuristic_agent(board, player)\n",
        "        else:\n",
        "            move = None\n",
        "            best_score = -math.inf if player == 1 else math.inf\n",
        "\n",
        "            for valid_move in get_valid_moves(board):\n",
        "                temp_board = board.copy()\n",
        "                apply_move(temp_board, valid_move, player)\n",
        "                score = minimax(temp_board, depth=3, maximizing_player=(player == 1))\n",
        "\n",
        "                if (player == 1 and score > best_score) or (player == -1 and score < best_score):\n",
        "                    best_score = score\n",
        "                    move = valid_move\n",
        "\n",
        "        apply_move(board, move, player)\n",
        "        moves.append((board.copy(), move, player))\n",
        "\n",
        "        winner = check_winner(board)\n",
        "        if winner is not None:\n",
        "            break\n",
        "\n",
        "        player *= -1\n",
        "\n",
        "        for board_state, move, player in moves:\n",
        "            reward = 1 if winner == player else -1 if winner == -player else 0\n",
        "            X_data.append(board_state)\n",
        "            y_data.append((move[0] * BOARD_SIZE + move[1], reward))\n",
        "\n",
        "    X_data = np.array(X_data).reshape(-1, BOARD_SIZE, BOARD_SIZE, 1)\n",
        "    y_data_moves = np.array([np.eye(BOARD_SIZE ** 2)[move] for move, _ in y_data])\n",
        "    y_data_rewards = np.array([reward for _, reward in y_data])\n",
        "\n",
        "    return X_data, y_data_moves, y_data_rewards\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Cross-entropy loss\n",
        "    base_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Penalize missing center move\n",
        "    center_penalty = tf.reduce_mean(tf.where(y_true[:, 4] == 1, 0.0, 1.0))  # Center is index 4 in a 3x3 flattened board\n",
        "\n",
        "    return base_loss + 0.1 * center_penalty  # Weight the penalty as needed\n",
        "\n",
        "\n",
        "# Build a regularized model with the updated loss\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model.add(Input(shape=(BOARD_SIZE, BOARD_SIZE, 1)))\n",
        "\n",
        "    # First convolutional block\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Second convolutional block\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Flatten and dense layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(BOARD_SIZE * BOARD_SIZE, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss=custom_loss,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Adjust training loop\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating training, validation, and test data...\")\n",
        "\n",
        "    X_train, y_train_moves, y_train_rewards = generate_training_data(8000)\n",
        "    X_val, y_val_moves, y_val_rewards = generate_training_data(1000)\n",
        "    X_test, y_test_moves, y_test_rewards = generate_training_data(1000)\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model()\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "\n",
        "    print(\"Training the model...\")\n",
        "    model.fit(\n",
        "        X_train, y_train_moves,\n",
        "        validation_data=(X_val, y_val_moves),\n",
        "        sample_weight=1 + y_train_rewards,  # Emphasizes rewards, including blocking\n",
        "        epochs=5,\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stopping, lr_scheduler]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    print(\"Evaluating the model on the test set...\")\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test_moves)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    model.save(\"GPT CNN Model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eVa3zp-y36A",
        "outputId": "9d80fd32-aa40-42e7-d6db-fe3fe3970204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training, validation, and test data...\n",
            "Training the model...\n",
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.0000e+00 - loss: 13.4396 - val_accuracy: 0.0000e+00 - val_loss: 11.6011 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3333 - loss: 11.0649 - val_accuracy: 0.6667 - val_loss: 11.4609 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6667 - loss: 10.9779 - val_accuracy: 0.6667 - val_loss: 11.3322 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.6667 - loss: 9.7971 - val_accuracy: 0.6667 - val_loss: 11.2112 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3333 - loss: 11.1889 - val_accuracy: 1.0000 - val_loss: 11.0957 - learning_rate: 0.0010\n",
            "Evaluating the model on the test set...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6667 - loss: 11.1207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT RNN"
      ],
      "metadata": {
        "id": "EQMs5xdLy9UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the Tic Tac Toe environment\n",
        "def initialize_board():\n",
        "    return np.zeros((3, 3), dtype=int)\n",
        "\n",
        "def is_winner(board, player):\n",
        "    for i in range(3):\n",
        "        if all(board[i, :] == player) or all(board[:, i] == player):\n",
        "            return True\n",
        "    if all([board[i, i] == player for i in range(3)]) or all([board[i, 2 - i] == player for i in range(3)]):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def is_draw(board):\n",
        "    return np.all(board != 0)\n",
        "\n",
        "def available_moves(board):\n",
        "    return [(i, j) for i in range(3) for j in range(3) if board[i, j] == 0]\n",
        "\n",
        "def make_move(board, move, player):\n",
        "    board[move] = player\n",
        "\n",
        "def generate_similar_games():\n",
        "    \"\"\"\n",
        "    Generate game states similar to the tournament scenarios where Model 3 struggled.\n",
        "    \"\"\"\n",
        "    games = []\n",
        "    for _ in range(100):\n",
        "        board = initialize_board()\n",
        "        # Example scenario: The opponent is about to win unless blocked\n",
        "        board[0, 2], board[1, 1], board[2, 0] = -1, -1, 0\n",
        "        games.append((board, -1))  # -1's turn\n",
        "\n",
        "        board = initialize_board()\n",
        "        # Example scenario: A winning move is available\n",
        "        board[0, 0], board[1, 1], board[0, 1] = 1, 1, 0\n",
        "        games.append((board, 1))  # 1's turn\n",
        "\n",
        "    return games\n",
        "\n",
        "# Define the RNN model\n",
        "def create_rnn_model():\n",
        "    model = Sequential([\n",
        "        SimpleRNN(128, activation=\"relu\", input_shape=(9, 1)),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(9, activation=\"linear\")\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "# Encode the board state\n",
        "def encode_board(board):\n",
        "    return board.flatten().reshape(1, 9, 1)\n",
        "\n",
        "# Choose a move based on the model's prediction\n",
        "def choose_move(model, board, epsilon=0.1):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return random.choice(available_moves(board))\n",
        "    predictions = model.predict(encode_board(board), verbose=0)\n",
        "    sorted_moves = np.argsort(predictions[0])[::-1]\n",
        "    for move in sorted_moves:\n",
        "        x, y = divmod(move, 3)\n",
        "        if (x, y) in available_moves(board):\n",
        "            return (x, y)\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, games, epochs=10):\n",
        "    x_train, y_train = [], []\n",
        "\n",
        "    for board, player in games:\n",
        "        moves = available_moves(board)\n",
        "        for move in moves:\n",
        "            temp_board = board.copy()\n",
        "            make_move(temp_board, move, player)\n",
        "\n",
        "            reward = 0\n",
        "            if is_winner(temp_board, player):\n",
        "                reward = 1\n",
        "            elif is_draw(temp_board):\n",
        "                reward = 0.5\n",
        "\n",
        "            x_train.append(encode_board(board).flatten())\n",
        "            target = model.predict(encode_board(board), verbose=0)[0]\n",
        "            target[move[0] * 3 + move[1]] = reward\n",
        "            y_train.append(target)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "    model.fit(x_train, y_train, epochs=epochs, verbose=1)\n",
        "\n",
        "# Self-play\n",
        "def self_play_training(model, iterations):\n",
        "    for _ in range(iterations):\n",
        "        state = np.zeros((3, 3))  # Initialize an empty board\n",
        "        player = 1\n",
        "        history = []\n",
        "\n",
        "        while True:\n",
        "            # Model chooses a move\n",
        "            encoded_state = encode_board(state).reshape(1, 9).astype(\"float32\")\n",
        "            predictions = model.predict(encoded_state, verbose=0).flatten()\n",
        "\n",
        "            # Pick the move with the highest value that's valid\n",
        "            valid_moves = [(i, j) for i in range(3) for j in range(3) if state[i, j] == 0]\n",
        "            move_values = {move: predictions[move[0] * 3 + move[1]] for move in valid_moves}\n",
        "            move = max(move_values, key=move_values.get)\n",
        "\n",
        "            # Apply the move\n",
        "            state[move] = player\n",
        "            history.append((state.copy(), player, move))\n",
        "\n",
        "            # Check if the game is over\n",
        "            winner = check_winner(state)\n",
        "            if winner is not None:\n",
        "                # Assign rewards for the moves in reverse order\n",
        "                reward = 1 if winner == player else -1\n",
        "                for past_state, past_player, past_move in reversed(history):\n",
        "                    target = model.predict(encode_board(past_state).reshape(1, 9).astype(\"float32\"), verbose=0).flatten()\n",
        "                    target[past_move[0] * 3 + past_move[1]] = reward\n",
        "                    reward *= 0.9  # Discount factor\n",
        "                    model.fit(\n",
        "                        encode_board(past_state).reshape(1, 9).astype(\"float32\"),\n",
        "                        target.reshape(1, -1),\n",
        "                        verbose=0,\n",
        "                    )\n",
        "                break\n",
        "\n",
        "            # Switch player\n",
        "            player = -player\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    model = create_rnn_model()\n",
        "\n",
        "    # Targeted training based on scenarios where Model 3 struggled\n",
        "    similar_games = generate_similar_games()\n",
        "    train_model(model, similar_games, epochs=20)\n",
        "\n",
        "    # Self-play to refine strategies\n",
        "    self_play_training(model, iterations=100)\n",
        "\n",
        "    # Save the updated model\n",
        "    model.save(\"GPT RNN Model.h5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdca0jbky-uy",
        "outputId": "ebb3e8c2-cf9e-46ec-d0fa-3fac85d803a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0133\n",
            "Epoch 2/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0131\n",
            "Epoch 3/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0139\n",
            "Epoch 4/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0134\n",
            "Epoch 5/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0133\n",
            "Epoch 6/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0144\n",
            "Epoch 7/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0131\n",
            "Epoch 8/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0128\n",
            "Epoch 9/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0134\n",
            "Epoch 10/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138\n",
            "Epoch 11/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127\n",
            "Epoch 12/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0136\n",
            "Epoch 13/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135\n",
            "Epoch 14/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0145\n",
            "Epoch 15/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0139\n",
            "Epoch 16/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130\n",
            "Epoch 17/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0140\n",
            "Epoch 18/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133\n",
            "Epoch 19/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0135\n",
            "Epoch 20/20\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPT TOURNAMENT"
      ],
      "metadata": {
        "id": "hsvnD42b6y_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import time\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "BOARD_SIZE = 3\n",
        "\n",
        "model1 = load_model(\"tictactoe_GPT_NN_model.h5\", compile=False)\n",
        "model1.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
        "\n",
        "model2 = load_model(\"/content/GPT CNN Model.h5\", compile=False)\n",
        "model2.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
        "\n",
        "model3 = load_model(\"/content/GPT RNN Model.h5\", compile=False)\n",
        "model3.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
        "custom_objects={\"mse\": MeanSquaredError()}\n",
        "model_names = {\n",
        "    model1: \"ChatGPT NN\",\n",
        "    model2: \"ChatGPT CNN\",\n",
        "    model3: \"ChatGPT RNN\"\n",
        "}\n",
        "def display_board(board):\n",
        "    symbols = {0: '.', 1: 'X', -1: 'O'}\n",
        "    for row in board:\n",
        "        print(\" \".join(symbols[cell] for cell in row))\n",
        "    print(\"\\n\")\n",
        "\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i, j] == 0]\n",
        "def apply_move(board, move, player):\n",
        "    board[move[0], move[1]] = player\n",
        "def check_winner(board):\n",
        "    for i in range(BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[:, i]))\n",
        "\n",
        "\n",
        "    if abs(sum([board[i, i] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, i] for i in range(BOARD_SIZE)]))\n",
        "    if abs(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)])) == BOARD_SIZE:\n",
        "        return np.sign(sum([board[i, BOARD_SIZE - i - 1] for i in range(BOARD_SIZE)]))\n",
        "\n",
        "    if 0 not in board:\n",
        "        return 0\n",
        "\n",
        "    return None\n",
        "def predict_move(model, board, player):\n",
        "    board_input = board.copy() * player\n",
        "\n",
        "    if len(model.input_shape) == 4 and model.input_shape[1:] == (3, 3, 1):\n",
        "        board_input = board_input.reshape(1, BOARD_SIZE, BOARD_SIZE, 1).astype(\"float32\")\n",
        "    elif len(model.input_shape) == 2 and model.input_shape[1] == 9:\n",
        "        board_input = board_input.reshape(1, BOARD_SIZE * BOARD_SIZE).astype(\"float32\")\n",
        "    elif len(model.input_shape) == 3 and model.input_shape[1:] == (9, 1):\n",
        "        board_input = board_input.reshape(1, BOARD_SIZE * BOARD_SIZE, 1).astype(\"float32\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected input shape for the model: {model.input_shape}\")\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    for move in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        apply_move(temp_board, move, player)\n",
        "        if check_winner(temp_board) == player:\n",
        "            return move\n",
        "\n",
        "    predictions = model.predict(board_input, verbose=0)[0].flatten()\n",
        "    move_probs = np.zeros_like(predictions)\n",
        "    for move in valid_moves:\n",
        "        idx = move[0] * BOARD_SIZE + move[1]\n",
        "        move_probs[idx] = predictions[idx]\n",
        "\n",
        "    best_move_idx = np.argmax(move_probs)\n",
        "    return (best_move_idx // BOARD_SIZE, best_move_idx % BOARD_SIZE)\n",
        "def play_game(model_a, model_b, game_num):\n",
        "    board = np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)\n",
        "    player = 1\n",
        "\n",
        "    print(f\"Game {game_num} starts:\")\n",
        "    while True:\n",
        "        print(f\"Player {player}'s turn:\")\n",
        "        display_board(board)\n",
        "\n",
        "        move = predict_move(model_a if player == 1 else model_b, board, player)\n",
        "        apply_move(board, move, player)\n",
        "        winner = check_winner(board)\n",
        "        if winner is not None:\n",
        "            print(\"\\nFinal Board:\")\n",
        "            display_board(board)\n",
        "            return winner\n",
        "\n",
        "        player *= -1\n",
        "def conduct_tournament(num_games=3):\n",
        "    models = [model1, model2, model3]\n",
        "    scores = {model_names[m]: 0 for m in models}\n",
        "    scores[\"Draw\"] = 0\n",
        "\n",
        "    game_num = 1\n",
        "    for i in range(len(models)):\n",
        "        for j in range(i + 1, len(models)):\n",
        "            model_a, model_b = models[i], models[j]\n",
        "            name_a, name_b = model_names[model_a], model_names[model_b]\n",
        "\n",
        "            for _ in range(num_games):\n",
        "                print(f\"{name_a} vs {name_b}\")\n",
        "                winner = play_game(model_a, model_b, game_num)\n",
        "                if winner == 1:\n",
        "                    print(f\"{name_a} wins!\\n\")\n",
        "                    scores[name_a] += 1\n",
        "                elif winner == -1:\n",
        "                    print(f\"{name_b} wins!\\n\")\n",
        "                    scores[name_b] += 1\n",
        "                else:\n",
        "                    print(\"It's a draw!\\n\")\n",
        "                    scores[\"Draw\"] += 1\n",
        "                game_num += 1\n",
        "                time.sleep(1)\n",
        "\n",
        "            for _ in range(num_games):\n",
        "                print(f\"{name_b} vs {name_a}\")\n",
        "                winner = play_game(model_b, model_a, game_num)\n",
        "                if winner == 1:\n",
        "                    print(f\"{name_b} wins!\\n\")\n",
        "                    scores[name_b] += 1\n",
        "                elif winner == -1:\n",
        "                    print(f\"{name_a} wins!\\n\")\n",
        "                    scores[name_a] += 1\n",
        "                else:\n",
        "                    print(\"It's a draw!\\n\")\n",
        "                    scores[\"Draw\"] += 1\n",
        "                game_num += 1\n",
        "                time.sleep(1)\n",
        "\n",
        "    print(\"Tournament Results:\")\n",
        "    for model, score in scores.items():\n",
        "        print(f\"{model}: {score}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    conduct_tournament(num_games=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMbJSCOj6xJ9",
        "outputId": "f2fd12b7-336f-457d-f075-3828973eedcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT NN vs ChatGPT CNN\n",
            "Game 1 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . .\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . X\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . X\n",
            "O O .\n",
            ". . .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "X X X\n",
            "O O .\n",
            ". . .\n",
            "\n",
            "\n",
            "ChatGPT NN wins!\n",
            "\n",
            "ChatGPT CNN vs ChatGPT NN\n",
            "Game 2 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . .\n",
            ". X .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "O . .\n",
            ". X .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "O . X\n",
            ". X .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "O . X\n",
            ". X .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "O . X\n",
            "X X .\n",
            "O . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "O . X\n",
            "X X O\n",
            "O . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "O . X\n",
            "X X O\n",
            "O . X\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "O O X\n",
            "X X O\n",
            "O . X\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "O O X\n",
            "X X O\n",
            "O X X\n",
            "\n",
            "\n",
            "It's a draw!\n",
            "\n",
            "ChatGPT NN vs ChatGPT RNN\n",
            "Game 3 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X . O\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "X . O\n",
            ". X .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "X O O\n",
            ". X .\n",
            ". . .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "X O O\n",
            ". X .\n",
            ". . X\n",
            "\n",
            "\n",
            "ChatGPT NN wins!\n",
            "\n",
            "ChatGPT RNN vs ChatGPT NN\n",
            "Game 4 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . X\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". . X\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". X X\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            "O X X\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            "O X X\n",
            ". O X\n",
            ". . .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "O X X\n",
            ". O X\n",
            ". . O\n",
            "\n",
            "\n",
            "ChatGPT NN wins!\n",
            "\n",
            "ChatGPT CNN vs ChatGPT RNN\n",
            "Game 5 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . .\n",
            ". X .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". . O\n",
            ". X .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . O\n",
            ". X .\n",
            "X . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". O O\n",
            ". X .\n",
            "X . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". O O\n",
            "X X .\n",
            "X . .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "O O O\n",
            "X X .\n",
            "X . .\n",
            "\n",
            "\n",
            "ChatGPT RNN wins!\n",
            "\n",
            "ChatGPT RNN vs ChatGPT CNN\n",
            "Game 6 starts:\n",
            "Player 1's turn:\n",
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". . X\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". . X\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player -1's turn:\n",
            ". X X\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "\n",
            "Player 1's turn:\n",
            ". X X\n",
            "O O .\n",
            ". . .\n",
            "\n",
            "\n",
            "\n",
            "Final Board:\n",
            "X X X\n",
            "O O .\n",
            ". . .\n",
            "\n",
            "\n",
            "ChatGPT RNN wins!\n",
            "\n",
            "Tournament Results:\n",
            "ChatGPT NN: 3\n",
            "ChatGPT CNN: 0\n",
            "ChatGPT RNN: 2\n",
            "Draw: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT vs DeepSeek and them combined vs a perfect model tournaments"
      ],
      "metadata": {
        "id": "maT7tc5J7LQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL TOURNAMENT"
      ],
      "metadata": {
        "id": "H-qNReWD7XoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from itertools import permutations\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "def load_models(model_paths):\n",
        "    return {path: tf.keras.models.load_model(path, compile=False) for path in model_paths}\n",
        "\n",
        "BOARD_SIZE = 3\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i, j] == 0]\n",
        "\n",
        "# Apply move\n",
        "def apply_move(board, move, player):\n",
        "    board[move[0], move[1]] = player\n",
        "\n",
        "# Check for a winner\n",
        "def check_winner(board):\n",
        "    for i in range(BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[:, i]))\n",
        "    if abs(sum(board.diagonal())) == BOARD_SIZE:\n",
        "        return np.sign(sum(board.diagonal()))\n",
        "    if abs(sum(np.fliplr(board).diagonal())) == BOARD_SIZE:\n",
        "        return np.sign(sum(np.fliplr(board).diagonal()))\n",
        "    if 0 not in board:\n",
        "        return 0\n",
        "    return None\n",
        "def predict_move(model, board, player):\n",
        "    input_shape = model.input_shape\n",
        "    board_input = board.copy() * player\n",
        "\n",
        "    if len(input_shape) == 4:\n",
        "        board_input = board_input.reshape(1, 3, 3, 1)\n",
        "    elif len(input_shape) == 3:\n",
        "        board_input = board_input.flatten().reshape(1, 9, 1)\n",
        "    elif len(input_shape) == 2:\n",
        "        board_input = board_input.flatten().reshape(1, 9)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported input shape: {input_shape}\")\n",
        "\n",
        "    predictions = model.predict(board_input, verbose=0)[0]\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    move_probs = np.zeros(BOARD_SIZE * BOARD_SIZE)\n",
        "\n",
        "    for move in valid_moves:\n",
        "        idx = move[0] * BOARD_SIZE + move[1]\n",
        "        move_probs[idx] = predictions[idx]\n",
        "\n",
        "    best_move_idx = np.argmax(move_probs)\n",
        "    return (best_move_idx // BOARD_SIZE, best_move_idx % BOARD_SIZE)\n",
        "def play_game(model1, model2):\n",
        "    board = np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)\n",
        "    player = 1\n",
        "    models = {1: model1, -1: model2}\n",
        "\n",
        "    while True:\n",
        "        move = predict_move(models[player], board, player)\n",
        "        if move not in get_valid_moves(board):\n",
        "            return -player\n",
        "        apply_move(board, move, player)\n",
        "\n",
        "        winner = check_winner(board)\n",
        "        if winner is not None:\n",
        "            return winner\n",
        "        player *= -1\n",
        "def run_tournament(model_paths):\n",
        "    models = load_models(model_paths)\n",
        "    scores = {name: 0 for name in model_paths}\n",
        "\n",
        "    for model1, model2 in permutations(model_paths, 2):\n",
        "        result = play_game(models[model1], models[model2])\n",
        "        if result == 1:\n",
        "            scores[model1] += 3\n",
        "        elif result == -1:\n",
        "            scores[model2] += 3\n",
        "        else:\n",
        "            scores[model1] += 1\n",
        "            scores[model2] += 1\n",
        "\n",
        "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"Tournament Results:\")\n",
        "    for idx, (model_name, score) in enumerate(sorted_scores):\n",
        "        print(f\"Rank {idx + 1}: {model_name} with {score} points\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_paths = [\n",
        "        \"DeepSeekRNN.h5\", \"DeepSeek CNN.h5\", \"DeepSeek NN.h5\", \"tictactoe_GPT_NN_model.h5\", \"GPT CNN Model.h5\", \"GPT RNN Model.h5\"\n",
        "    ]\n",
        "    run_tournament(model_paths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6LMPbUy0Oyg",
        "outputId": "c6b3220f-bab1-48e5-d6ec-d3460380df43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tournament Results:\n",
            "Rank 1: DeepSeek NN.h5 with 23 points\n",
            "Rank 2: tictactoe_GPT_NN_model.h5 with 21 points\n",
            "Rank 3: DeepSeek CNN.h5 with 16 points\n",
            "Rank 4: GPT RNN Model.h5 with 12 points\n",
            "Rank 5: GPT CNN Model.h5 with 7 points\n",
            "Rank 6: DeepSeekRNN.h5 with 4 points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOURNAMENT VS MY MODEL"
      ],
      "metadata": {
        "id": "wlUHaKh91lrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "BOARD_SIZE = 3\n",
        "NUM_MODELS = 6\n",
        "\n",
        "def load_models(model_paths):\n",
        "    return [tf.keras.models.load_model(path, compile=False) for path in model_paths]\n",
        "\n",
        "def get_valid_moves(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i, j] == 0]\n",
        "\n",
        "def apply_move(board, move, player):\n",
        "    board[move[0], move[1]] = player\n",
        "\n",
        "\n",
        "def check_winner(board):\n",
        "    for i in range(BOARD_SIZE):\n",
        "        if abs(sum(board[i, :])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[i, :]))\n",
        "        if abs(sum(board[:, i])) == BOARD_SIZE:\n",
        "            return np.sign(sum(board[:, i]))\n",
        "    if abs(sum(board.diagonal())) == BOARD_SIZE:\n",
        "        return np.sign(sum(board.diagonal()))\n",
        "    if abs(sum(np.fliplr(board).diagonal())) == BOARD_SIZE:\n",
        "        return np.sign(sum(np.fliplr(board).diagonal()))\n",
        "    if 0 not in board:\n",
        "        return 0\n",
        "    return None\n",
        "\n",
        "def predict_move(model, board, player):\n",
        "    input_shape = model.input_shape\n",
        "    board_input = board.copy() * player\n",
        "\n",
        "    if len(input_shape) == 4:\n",
        "        board_input = board_input.reshape(1, 3, 3, 1)\n",
        "    elif len(input_shape) == 3:\n",
        "        board_input = board_input.flatten().reshape(1, 9, 1)\n",
        "    elif len(input_shape) == 2:\n",
        "        board_input = board_input.flatten().reshape(1, 9)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported input shape: {input_shape}\")\n",
        "\n",
        "    predictions = model.predict(board_input, verbose=0)[0]\n",
        "\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    move_probs = np.zeros(BOARD_SIZE * BOARD_SIZE)\n",
        "\n",
        "    for move in valid_moves:\n",
        "        idx = move[0] * BOARD_SIZE + move[1]\n",
        "        move_probs[idx] = predictions[idx]\n",
        "\n",
        "    best_move_idx = np.argmax(move_probs)\n",
        "    return (best_move_idx // BOARD_SIZE, best_move_idx % BOARD_SIZE)\n",
        "\n",
        "def play_game(model1, model2):\n",
        "    board = np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)\n",
        "    player = 1\n",
        "    models = {1: model1, -1: model2}\n",
        "\n",
        "    while True:\n",
        "        move = predict_move(models[player], board, player)\n",
        "        if move not in get_valid_moves(board):\n",
        "            return -player\n",
        "        apply_move(board, move, player)\n",
        "\n",
        "        winner = check_winner(board)\n",
        "        if winner is not None:\n",
        "            return winner\n",
        "        player *= -1\n",
        "\n",
        "def evaluate_models(model_paths, reference_model_path):\n",
        "    models = load_models(model_paths)\n",
        "    reference_model = tf.keras.models.load_model(reference_model_path, compile=False)\n",
        "\n",
        "    results = {i: {'wins': 0, 'draws': 0, 'losses': 0} for i in range(NUM_MODELS)}\n",
        "    ref_results = {'wins': 0, 'draws': 0, 'losses': 0}  # Reference model stats\n",
        "\n",
        "    for i in range(NUM_MODELS):\n",
        "        result = play_game(models[i], reference_model)\n",
        "        if result == 1:\n",
        "            results[i]['wins'] += 1\n",
        "            ref_results['losses'] += 1\n",
        "        elif result == -1:\n",
        "            results[i]['losses'] += 1\n",
        "            ref_results['wins'] += 1\n",
        "        else:\n",
        "            results[i]['draws'] += 1\n",
        "            ref_results['draws'] += 1\n",
        "\n",
        "\n",
        "        result = play_game(reference_model, models[i])\n",
        "        if result == -1:\n",
        "            results[i]['wins'] += 1\n",
        "            ref_results['losses'] += 1\n",
        "        elif result == 1:\n",
        "            results[i]['losses'] += 1\n",
        "            ref_results['wins'] += 1\n",
        "        else:\n",
        "            results[i]['draws'] += 1\n",
        "            ref_results['draws'] += 1\n",
        "\n",
        "\n",
        "    print(\"\\nEvaluation Results against Reference Model:\")\n",
        "    for model_idx, score in results.items():\n",
        "        print(f\"Model {model_idx}: {score['wins']} Wins, {score['draws']} Draws, {score['losses']} Losses\")\n",
        "\n",
        "\n",
        "    print(\"\\nReference Model Performance:\")\n",
        "    print(f\"Wins: {ref_results['wins']}, Draws: {ref_results['draws']}, Losses: {ref_results['losses']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_paths = [\n",
        "        \"DeepSeekRNN.h5\", \"DeepSeek CNN.h5\", \"DeepSeek NN.h5\", \"tictactoe_GPT_NN_model.h5\", \"GPT CNN Model.h5\", \"GPT RNN Model.h5\"\n",
        "    ]\n",
        "    reference_model_path = \"/content/tic_tac_toe_nn_vtorobid_tf.keras\"\n",
        "    evaluate_models(model_paths, reference_model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PmPRqWc1n7j",
        "outputId": "b51e2936-7761-4e09-d9bf-1a1eb697f6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results against Reference Model:\n",
            "Model 0: 0 Wins, 0 Draws, 2 Losses\n",
            "Model 1: 0 Wins, 0 Draws, 2 Losses\n",
            "Model 2: 0 Wins, 1 Draws, 1 Losses\n",
            "Model 3: 0 Wins, 2 Draws, 0 Losses\n",
            "Model 4: 0 Wins, 1 Draws, 1 Losses\n",
            "Model 5: 0 Wins, 0 Draws, 2 Losses\n",
            "\n",
            "Reference Model Performance:\n",
            "Wins: 8, Draws: 4, Losses: 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}